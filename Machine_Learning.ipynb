{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO92luiedP7g2XsZtqQhI2u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rafaelfyh/Challenge_DataScience/blob/main/Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como Entregar esse projeto?\n",
        "Chegou a hora de você construir um portfólio ainda mais rico e impressionar futuros recrutadores, para isso é sempre importante mostrar os resultados do seu esforço e como você os obteve deixando claro o seu racional, para isso faça da seguinte maneira:\n",
        "\n",
        "Criar um modelo de previsão com seus devidos pontos de extremidade configurados\n",
        "\n",
        "\n",
        "4. Salve nesse repositório o readme.md e o arquivo .json de pontos de extremidade\n",
        "5. Compartilhe conosco o link desse repositório através do botão 'entregar projeto'"
      ],
      "metadata": {
        "id": "UIXYoTQI8Rty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ik8daQ_T2xTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Carregar o arquivo CSV\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "zaEBbahj4sRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar o arquivo CSV em um DataFrame\n",
        "df = pd.read_csv('/content/VendasSupermercados+CDI.csv')\n"
      ],
      "metadata": {
        "id": "bWGMqVhi4uy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar os dados\n",
        "df = pd.read_csv('/content/VendasSupermercados+CDI.csv')\n",
        "\n",
        "# Exibir as primeiras linhas do DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "ePpZ5miP5rfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar os dados\n",
        "df = pd.read_csv('/content/VendasSupermercados+CDI.csv', sep=';')\n",
        "\n",
        "# Exibir as primeiras linhas do DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "xjNli-yC52ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar os dados\n",
        "df = pd.read_csv('/content/VendasSupermercados+CDI.csv')\n",
        "\n",
        "# Exibir as primeiras linhas do DataFrame\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "08XgZ6LH7AT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar os primeiros dados do arquivo CSV para inspecionar\n",
        "with open('/content/VendasSupermercados+CDI.csv', 'r') as file:\n",
        "    for _ in range(5):  # Ler as primeiras 5 linhas\n",
        "        print(file.readline())\n",
        "\n"
      ],
      "metadata": {
        "id": "rtMNQ_n-7RAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar os dados com o ponto e vírgula (;) como delimitador\n",
        "df = pd.read_csv('/content/VendasSupermercados+CDI.csv', delimiter=';')\n",
        "\n",
        "# Exibir as primeiras linhas do DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "iCFhPq327c3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Carregar os dados\n",
        "df = pd.read_csv('/content/VendasSupermercados+CDI.csv', delimiter=';')\n",
        "\n",
        "# Converter a coluna 'Date' para datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Calcular a diferença em dias entre a data atual e a data de referência (primeira data no conjunto de dados)\n",
        "reference_date = df['Date'].min()\n",
        "df['Days_since_reference'] = (df['Date'] - reference_date).dt.days\n",
        "\n",
        "# Dividir os dados em características (X) e alvo (y)\n",
        "X = df[['Days_since_reference', 'CDI']].values  # 'Days_since_reference' e 'CDI' como características\n",
        "y = df['VendasSupermercados'].values\n",
        "\n",
        "# Dividir os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizar os dados\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Criar o modelo de regressão\n",
        "model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Treinar o modelo\n",
        "history = model.fit(X_train_scaled, y_train, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Avaliar o modelo\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n"
      ],
      "metadata": {
        "id": "JFIpoCVb7lbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#######################"
      ],
      "metadata": {
        "id": "Gryj8ZR-892H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Passo a passo desse processo até a solução readme.md  "
      ],
      "metadata": {
        "id": "Msvi6gaE8qLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de Previsão de Vendas de Supermercados\n",
        "\n",
        "Este repositório contém um modelo de previsão de vendas de supermercados utilizando uma rede neural artificial implementada com TensorFlow. O modelo prevê as vendas de supermercados com base na data e na taxa CDI (Certificado de Depósito Interbancário).\n",
        "\n",
        "## Passos\n",
        "\n",
        "1. **Obtenção dos Dados:** Os dados foram obtidos de um arquivo CSV contendo informações de vendas de supermercados e a taxa CDI ao longo do tempo.\n",
        "\n",
        "2. **Pré-processamento dos Dados:** Inicialmente, o arquivo CSV foi carregado utilizando a biblioteca pandas. Em seguida, a coluna 'Date' foi convertida para o formato de data utilizando a função `pd.to_datetime()`. Além disso, foi calculada a diferença em dias entre a data atual e a data de referência para obter uma representação numérica da data.\n",
        "\n",
        "3. **Divisão dos Dados:** Os dados foram divididos em características (X) e alvo (y). As características incluem a representação numérica da data ('Days_since_reference') e a taxa CDI. O conjunto de dados foi dividido em conjuntos de treinamento e teste utilizando a função `train_test_split()`.\n",
        "\n",
        "4. **Normalização dos Dados:** Os dados foram normalizados utilizando o `StandardScaler` da biblioteca sklearn para garantir que todas as características tenham a mesma escala.\n",
        "\n",
        "5. **Criação do Modelo:** O modelo de previsão foi criado utilizando a API sequencial do TensorFlow. O modelo consiste em duas camadas densas com ativação ReLU e uma camada de saída. A função de perda utilizada foi o erro quadrático médio (MSE), e o otimizador utilizado foi o Adam.\n",
        "\n",
        "6. **Treinamento do Modelo:** O modelo foi treinado utilizando o método `fit()` do TensorFlow com os dados de treinamento. Foram realizadas 10 épocas de treinamento com uma divisão de validação de 20%.\n",
        "\n",
        "7. **Avaliação do Modelo:** Após o treinamento, o modelo foi avaliado utilizando os dados de teste. O erro médio quadrático (MSE) foi calculado para avaliar o desempenho do modelo.\n",
        "\n",
        "## Resultados\n",
        "\n",
        "O modelo treinado apresentou um MSE de aproximadamente 8443.54 nos dados de teste. Isso sugere que o modelo pode não estar generalizando bem para dados não vistos e pode precisar de ajustes adicionais.\n",
        "\n"
      ],
      "metadata": {
        "id": "r2C3phMv8iV4"
      }
    }
  ]
}